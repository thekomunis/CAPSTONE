# -*- coding: utf-8 -*-
"""Model_Input

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xbIgS4DqC3pZyUavqfPajySAs3rldua2

# **1. Import Library**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score

"""# **2. Data Understanding**

### 2.1 Data Loading
"""

# Load and clean data
file_path = "cleaned_animal_disease_prediction.csv"
df = pd.read_csv(file_path).drop(columns=['Animal_Type'])
df.head()

"""# **3. Exploratory Data Analysis (EDA)**"""

#Meninjau jumlah baris dan kolom dataset
jumlah_baris, jumlah_kolom = df.shape

print(f"Jumlah baris (rows): {jumlah_baris}")
print(f"Jumlah kolom (columns): {jumlah_kolom}")

#Menampilkan informasi dataset
df.info()

#Memeriksa Missing Values pada dataset
df.isnull().sum()

## ringkasan statistik dataset
df.describe()

#menampilkan jumlah label kolom Disease
df['Disease_Prediction'].value_counts()

#Visualisasi data numerik menggunakan histogram dan boxplot
numerical_cols = ['Age', 'Weight', 'Heart_Rate']
fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
fig.suptitle("Visualisasi Data Numerikal", fontsize=16)

for i, col in enumerate(numerical_cols):
    sns.histplot(df[col], kde=True, ax=axes[i][0], color='skyblue')
    axes[i][0].set_title(f'Histogram of {col}')
    sns.boxplot(x=df[col], ax=axes[i][1], color='lightgreen')
    axes[i][1].set_title(f'Boxplot of {col}')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

categorical_cols = df.select_dtypes(include='object').columns.tolist()
ncols, nrows = 2, (len(categorical_cols) + 1) // 2
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, nrows * 4))
fig.suptitle("Visualisasi Data Kategorikal", fontsize=20)
axes = axes.flatten()

for i, col in enumerate(categorical_cols):
    top_categories = df[col].value_counts().nlargest(20).index
    sns.countplot(data=df[df[col].isin(top_categories)], x=col, order=top_categories, ax=axes[i], palette="Set2")
    axes[i].set_title(f'Count Plot of {col}', fontsize=14)
    axes[i].tick_params(axis='x', rotation=90)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# Pairplot untuk hubungan antar variabel numerikal
sns.pairplot(df.select_dtypes(include=[np.number]))
plt.suptitle("Pairplot Antar Variabel Numerik", y=1.02)
plt.show()

"""## **4. Data Preparation**"""

binary_mapping = {'No': 0, 'Yes': 1, 'Male': 0, 'Female': 1}
for col in ['Gender', 'Appetite_Loss', 'Vomiting', 'Diarrhea', 'Coughing',
            'Labored_Breathing', 'Lameness', 'Skin_Lesions',
            'Nasal_Discharge', 'Eye_Discharge']:
    df[col] = df[col].replace(binary_mapping).infer_objects(copy=False)

# Inisialisasi label encoder
le = LabelEncoder()

# Fit encoder ke kolom Disease_Prediction
df['Disease_Prediction_encoded'] = le.fit_transform(df['Disease_Prediction'])

# Buat dictionary mapping
label_mapping = {index: label for index, label in enumerate(le.classes_)}

# Tampilkan mapping
for key, value in label_mapping.items():
    print(f"{key}: {value}")

# Label Encoding
label_encoders = {}
categorical_cols = ['Breed', 'Symptom_1', 'Symptom_2', 'Symptom_3', 'Symptom_4',
                    'Duration', 'Body_Temperature', 'Disease_Prediction']
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

df.head()

df.info()

label_counts = df['Disease_Prediction'].value_counts()
valid_labels = label_counts[label_counts >= 9].index
filtered_df = df[df['Disease_Prediction'].isin(valid_labels)]

# Split data
X = filtered_df.drop(columns=['Disease_Prediction'])
y = filtered_df['Disease_Prediction']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

"""## **5. Modelling & Evaluation**

### 5.1 Latih Model dengan Random Forest
"""

rf_model = RandomForestClassifier(n_estimators=50, max_depth=15, random_state=42)
rf_model.fit(X_train, y_train)

y_train_pred = rf_model.predict(X_train)
y_test_pred = rf_model.predict(X_test)

print("Random Forest Evaluation")
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred):.2%}, F1: {f1_score(y_train, y_train_pred, average='weighted'):.2f}")
print(f"Test Accuracy: {accuracy_score(y_test, y_test_pred):.2%}, F1: {f1_score(y_test, y_test_pred, average='weighted'):.2f}")

"""### 5.2 Latih Model dengan XG Boost"""

le = LabelEncoder()
y_encoded = le.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)

xgb_model = XGBClassifier(objective='multi:softmax', num_class=len(le.classes_),
                          eval_metric='mlogloss', use_label_encoder=False, random_state=42)
xgb_model.fit(X_train, y_train)
y_train_pred = xgb_model.predict(X_train)
y_test_pred = xgb_model.predict(X_test)
print("XGBoost Evaluation")
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred):.2%}, F1: {f1_score(y_train, y_train_pred, average='weighted'):.2f}")
print(f"Test Accuracy: {accuracy_score(y_test, y_test_pred):.2%}, F1: {f1_score(y_test, y_test_pred, average='weighted'):.2f}")

"""## **6. Tunning**"""

# Hyperparameter Tuning - Random Forest
rf_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
rf_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_params,
                               n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)
rf_search.fit(X_train, y_train)
print("Best Random Forest Params:", rf_search.best_params_)
print("Best Score:", rf_search.best_score_)

xgb_params = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0]
}
xgb_search = RandomizedSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),
                                xgb_params, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)
xgb_search.fit(X_train, y_train)
print("Best XGBoost Params:", xgb_search.best_params_)
print("Best Score:", xgb_search.best_score_)

best_model = rf_search.best_estimator_  # atau xgb_search.best_estimator_, dst.
best_model.predict(X_test)

best_model = xgb_search.best_estimator_
best_model.predict(X_test)

"""## **Konversi Model**

Menyimpan dan Memuat Model (Deployment ke Backend)
"""

# Simpan model
joblib.dump(rf_model, "best_model.pkl")
# Menyimpan label encoder
joblib.dump(label_encoders, "label_encoders.pkl")

"""# **Testing**"""

# Load model
model = joblib.load("best_model.pkl")

# Jika ada scaler, load juga
try:
    scaler = joblib.load("scaler.pkl")
except:
    scaler = None

# Jika ada label encoder, load
try:
    label_encoders = joblib.load("label_encoders.pkl")
except:
    label_encoders = None

# Ambil satu sample dari data uji
input_df = X_test.iloc[[0]]
print("Data input:\n", input_df)

# Simpan label aslinya (jika ingin dibandingkan)
true_label = y_test[0]

# Scaling jika diperlukan
if scaler:
    input_scaled = scaler.transform(input_df)
else:
    input_scaled = input_df

# Prediksi kelas
prediksi = model.predict(input_scaled)[0]

# Probabilitas prediksi
if hasattr(model, "predict_proba"):
    proba = model.predict_proba(input_scaled)
    class_index = list(model.classes_).index(prediksi)
    confidence = proba[0][class_index] * 100
else:
    confidence = "N/A"

# Decode label jika perlu
if label_encoders and 'Disease_Prediction' in label_encoders:
    prediksi_label = label_encoders['Disease_Prediction'].inverse_transform([prediksi])[0]
    true_label = label_encoders['Disease_Prediction'].inverse_transform([true_label])[0]
else:
    prediksi_label = prediksi

# Tampilkan hasil
print(f"Hasil Prediksi: {prediksi_label}")
print(f"Akurasi Prediksi (confidence): {confidence:.2f}%")
print(f"Label Sebenarnya: {true_label}")

"""Mengkonversi untuk Web Deployment (Flask, FastAPI)"""

import json

with open("disease_mapping.json", "w") as f:
    json.dump(label_mapping, f)

with open("disease_mapping.json", "r") as f:
    mapping = json.load(f)

# Simpan ulang dalam format yang rapi
with open("disease_mapping_pretty.json", "w") as f:
    json.dump(mapping, f, indent=4)

from flask import Flask, request, jsonify

app = Flask(__name__)
model = joblib.load('best_model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    input_data = request.json
    input_df = pd.DataFrame([input_data])
    prediction = model.predict(input_df)[0]
    return jsonify({'prediction': int(prediction)})

if __name__ == '__main__':
    app.run()